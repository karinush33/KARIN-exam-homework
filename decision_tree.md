# תשובות – קובץ 30  
## Decision Tree

### 1. האם מודל Decision Tree פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?
גם וגם.  
בקלסיפיקציה- מנסה לייצר קבוצות עם רוב מסוים לקבוצה מסוימת- וככה הוא יכול לנחש יותר טוב.  
ברגרסיה- אני צריכה לייצר קבוצות, שכמה שיותר קרובות לממוצע.

---

### 2. מהו הרעיון המרכזי שעליו מבוסס מודל Decision Tree?
פיצול הדאטה בסדרה של “אם/אז” לפי פיצ’רים, כדי להגיע לעלים (leaves) שבהם התוצאה כמה שיותר אחידה.

---

### 3. מהו Gini Impurity?
מראה את רמת "הטהירות" של קבוצה מסוימת-כמה הקבוצה מעורבבת או טהורה.

---

### 4. כיצד Gini Impurity מודד את איכות הפיצול?
הוא מחזיר כשהג'יני אימפיוריטי 0- לגמרי טהורה. 1- הכי מעורבבת. (50\50)

---

### 5. מה הערך של Gini Impurity כאשר הצומת "טהור" לחלוטין?
0

---

### 6. מהי מטרת הפיצול בכל צומת בעץ?
להשיג קבוצות שיש להם יותר רוב, כי אז הניחוש שלי יהיה יותר טוב.

---

### 7. הסבר את תצורת הפיצול בעץ כאשר מדובר בבעיית רגרסיה
בפיצול של בעיית ריגרסיה אני מנסה להשיג בכל פיצול- MSE שהוא יותר נמוך.

---

### 8. כאשר הגענו לתחתית העץ כיצד ניתן תחזית בקלאסיפיקציה וברגרסיה?
ברגרסיה: הערך החזוי בעלה הוא לרוב הממוצע של ערכי y של הדוגמאות שהגיעו לעלה.  
בקלסיפיקציה: המחלקה החזויה היא לרוב הרוב בעלה (או הסתברויות לפי התפלגות).

---

### 9. אילו Hyperparameters נפוצים קיימים ב־Decision Tree?
עומק מקסימלי, מינימום דגימות לפיצול.

---

### 10. כיצד עומק העץ (Tree Depth) משפיע על Overfitting ו־Underfitting?
מה קורה כאשר העץ עמוק מאוד?  
מה קורה כאשר העץ רדוד מאוד?  

תשובה: עץ עמוק מאוד = Overfitting. עץ רדוד מאוד = Underfitting  
עץ עמוק מדי לומד כל מקרה ספציפי (כולל טעויות). עץ רדוד מדי פשוט מדי ולא לומד את המורכבות.

---

### 11. אילו מדדי ביצוע מתאימים להערכת מודל Decision Tree בקלסיפיקציה וברגרסיה?
קלסיפיקציה: Accuracy. רגרסיה: MSE, R^2.
